# TD_Local_RAG

Локальная система Retrieval-Augmented Generation (RAG) для работы с собственными документами с использованием локальной LLM.

## Возможности

- Создание индекса документов (.txt и .md файлы)
- Использование локальной LLM модели через API сервер
- Векторизация документов для эффективного поиска
- Интерактивный и командный режимы для задавания вопросов

## Установка

1. Клонировать репозиторий
```bash
git clone https://github.com/Ballindaboy/TD_Local_RAG.git
cd TD_Local_RAG
```

2. Создать виртуальное окружение Python
```bash
python3 -m venv venv
source venv/bin/activate
```

3. Установить зависимости
```bash
pip install -r requirements.txt
```

## Использование

### 1. Добавление документов

Поместите ваши текстовые (.txt) и markdown (.md) файлы в папку `data/`.

### 2. Создание индекса

Запустите скрипт для индексации документов:
```bash
python3 rag.py
```

### 3. Задавание вопросов

Используйте скрипт `ask.py` для получения ответов на основе ваших документов:
```bash
python3 ask.py "Ваш вопрос здесь?"
```

## Требования

- Python 3.10+
- Локальный LLM сервер, работающий по адресу http://127.0.0.1:1234
- Поддержка llama-3.2-3b-instruct или другой совместимой модели

## Примечание по безопасности

- Не включайте конфиденциальные данные в публичный репозиторий
- Используйте .env файл для хранения API ключей (не включен в репозиторий)
- Локальная модель обеспечивает конфиденциальность данных

## Лицензия

MIT